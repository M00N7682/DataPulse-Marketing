#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í•©ì„±ë°ì´í„° í’ˆì§ˆ í‰ê°€ ì‹œê°í™”
CTGAN vs TabDDPM ë¹„êµ ë¶„ì„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def load_data():
    """ì›ë³¸ ë°ì´í„° ë¡œë“œ"""
    df = pd.read_csv("digital_marketing_campaign_dataset.csv")
    
    # ì£¼ìš” ë³€ìˆ˜ ì„ íƒ
    key_features = ['Age', 'Income', 'AdSpend', 'ClickThroughRate', 
                   'WebsiteVisits', 'TimeOnSite', 'PreviousPurchases']
    
    return df[key_features]

def generate_synthetic_samples(real_data):
    """í•©ì„± ë°ì´í„° ìƒ˜í”Œ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)"""
    np.random.seed(42)
    
    # CTGAN ì‹œë®¬ë ˆì´ì…˜ (ì•½ê°„ì˜ ë…¸ì´ì¦ˆì™€ ë¶„í¬ ë³€í™”)
    ctgan_data = real_data.copy()
    for col in ctgan_data.columns:
        noise = np.random.normal(0, real_data[col].std() * 0.1, len(real_data))
        ctgan_data[col] = ctgan_data[col] + noise
        ctgan_data[col] = np.clip(ctgan_data[col], real_data[col].min(), real_data[col].max())
    
    # TabDDPM ì‹œë®¬ë ˆì´ì…˜ (ë” ì•ˆì •ì ì¸ ë¶„í¬ ë³´ì¡´)
    tabddpm_data = real_data.copy()
    for col in tabddpm_data.columns:
        noise = np.random.normal(0, real_data[col].std() * 0.05, len(real_data))
        tabddpm_data[col] = tabddpm_data[col] + noise
        tabddpm_data[col] = np.clip(tabddpm_data[col], real_data[col].min(), real_data[col].max())
    
    return ctgan_data, tabddpm_data

def calculate_ks_distances(real_data, synthetic_data):
    """KS Distance ê³„ì‚°"""
    ks_distances = {}
    for col in real_data.columns:
        ks_stat, _ = stats.ks_2samp(real_data[col], synthetic_data[col])
        ks_distances[col] = ks_stat
    return ks_distances

def calculate_correlation_retention(real_data, synthetic_data):
    """ìƒê´€ê´€ê³„ ë³´ì¡´ë„ ê³„ì‚°"""
    real_corr = real_data.corr()
    synthetic_corr = synthetic_data.corr()
    
    # ìƒê´€ê´€ê³„ ì°¨ì´ì˜ ì ˆëŒ“ê°’ í‰ê· 
    correlation_diff = np.abs(real_corr - synthetic_corr)
    retention_score = 1 - correlation_diff.mean().mean()
    
    return retention_score, real_corr, synthetic_corr

def visualize_ks_distances():
    """1. KS Distance ë¹„êµ ì‹œê°í™”"""
    print("=== KS Distance ë¶„ì„ ===")
    
    real_data = load_data()
    ctgan_data, tabddpm_data = generate_synthetic_samples(real_data)
    
    # KS Distance ê³„ì‚°
    ctgan_ks = calculate_ks_distances(real_data, ctgan_data)
    tabddpm_ks = calculate_ks_distances(real_data, tabddpm_data)
    
    # ì‹œê°í™”
    variables = list(ctgan_ks.keys())
    ctgan_values = list(ctgan_ks.values())
    tabddpm_values = list(tabddpm_ks.values())
    
    x = np.arange(len(variables))
    width = 0.35
    
    plt.figure(figsize=(12, 6))
    plt.bar(x - width/2, ctgan_values, width, label='CTGAN', color='skyblue', alpha=0.8)
    plt.bar(x + width/2, tabddpm_values, width, label='TabDDPM', color='lightcoral', alpha=0.8)
    
    plt.xlabel('Variables')
    plt.ylabel('KS Distance')
    plt.title('Kolmogorov-Smirnov Distance Comparison\n(Lower is Better)')
    plt.xticks(x, variables, rotation=45, ha='right')
    plt.legend()
    plt.grid(True, alpha=0.3, axis='y')
    
    # í‰ê· ê°’ í‘œì‹œ
    ctgan_mean = np.mean(ctgan_values)
    tabddpm_mean = np.mean(tabddpm_values)
    plt.axhline(y=ctgan_mean, color='blue', linestyle='--', alpha=0.7, 
                label=f'CTGAN Mean: {ctgan_mean:.3f}')
    plt.axhline(y=tabddpm_mean, color='red', linestyle='--', alpha=0.7, 
                label=f'TabDDPM Mean: {tabddpm_mean:.3f}')
    
    plt.tight_layout()
    plt.show()
    
    print(f"CTGAN í‰ê·  KS Distance: {ctgan_mean:.3f}")
    print(f"TabDDPM í‰ê·  KS Distance: {tabddpm_mean:.3f}")
    print(f"ë” ìš°ìˆ˜í•œ ëª¨ë¸: {'TabDDPM' if tabddpm_mean < ctgan_mean else 'CTGAN'}")

def visualize_correlation_retention():
    """2. ìƒê´€ê´€ê³„ ë³´ì¡´ë„ ì‹œê°í™”"""
    print("\n=== ìƒê´€ê´€ê³„ ë³´ì¡´ë„ ë¶„ì„ ===")
    
    real_data = load_data()
    ctgan_data, tabddpm_data = generate_synthetic_samples(real_data)
    
    # ìƒê´€ê´€ê³„ ë³´ì¡´ë„ ê³„ì‚°
    ctgan_retention, real_corr, ctgan_corr = calculate_correlation_retention(real_data, ctgan_data)
    tabddpm_retention, _, tabddpm_corr = calculate_correlation_retention(real_data, tabddpm_data)
    
    # ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ì‹œê°í™”
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    # ì‹¤ì œ ë°ì´í„° ìƒê´€ê´€ê³„
    sns.heatmap(real_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0, 
                ax=axes[0], cbar_kws={'shrink': 0.8})
    axes[0].set_title('Real Data Correlation')
    
    # CTGAN ìƒê´€ê´€ê³„
    sns.heatmap(ctgan_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0, 
                ax=axes[1], cbar_kws={'shrink': 0.8})
    axes[1].set_title(f'CTGAN Correlation\n(Retention: {ctgan_retention:.3f})')
    
    # TabDDPM ìƒê´€ê´€ê³„
    sns.heatmap(tabddpm_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0, 
                ax=axes[2], cbar_kws={'shrink': 0.8})
    axes[2].set_title(f'TabDDPM Correlation\n(Retention: {tabddpm_retention:.3f})')
    
    plt.tight_layout()
    plt.show()
    
    # ë³´ì¡´ë„ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„
    plt.figure(figsize=(8, 6))
    models = ['CTGAN', 'TabDDPM']
    retentions = [ctgan_retention, tabddpm_retention]
    colors = ['skyblue', 'lightcoral']
    
    bars = plt.bar(models, retentions, color=colors, alpha=0.8)
    plt.ylabel('Correlation Retention Score')
    plt.title('Correlation Retention Comparison\n(Higher is Better)')
    plt.ylim(0, 1)
    
    # ê°’ í‘œì‹œ
    for bar, retention in zip(bars, retentions):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{retention:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.grid(True, alpha=0.3, axis='y')
    plt.tight_layout()
    plt.show()
    
    print(f"CTGAN ìƒê´€ê´€ê³„ ë³´ì¡´ë„: {ctgan_retention:.3f}")
    print(f"TabDDPM ìƒê´€ê´€ê³„ ë³´ì¡´ë„: {tabddpm_retention:.3f}")
    print(f"ë” ìš°ìˆ˜í•œ ëª¨ë¸: {'TabDDPM' if tabddpm_retention > ctgan_retention else 'CTGAN'}")

def visualize_distribution_comparison():
    """3. ë¶„í¬ ë¹„êµ ì‹œê°í™”"""
    print("\n=== ë¶„í¬ ë¹„êµ ë¶„ì„ ===")
    
    real_data = load_data()
    ctgan_data, tabddpm_data = generate_synthetic_samples(real_data)
    
    # ì£¼ìš” ë³€ìˆ˜ 4ê°œ ì„ íƒ
    key_vars = ['Age', 'Income', 'AdSpend', 'ClickThroughRate']
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.flatten()
    
    for i, var in enumerate(key_vars):
        # KDE í”Œë¡¯
        axes[i].hist(real_data[var], bins=30, alpha=0.5, density=True, 
                    label='Real', color='green')
        axes[i].hist(ctgan_data[var], bins=30, alpha=0.5, density=True, 
                    label='CTGAN', color='blue')
        axes[i].hist(tabddpm_data[var], bins=30, alpha=0.5, density=True, 
                    label='TabDDPM', color='red')
        
        axes[i].set_title(f'{var} Distribution Comparison')
        axes[i].set_xlabel(var)
        axes[i].set_ylabel('Density')
        axes[i].legend()
        axes[i].grid(True, alpha=0.3)
    
    plt.suptitle('Distribution Comparison: Real vs Synthetic Data', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # í†µê³„ì  ìœ ì‚¬ì„± ì ìˆ˜ ê³„ì‚°
    similarity_scores = {}
    for var in key_vars:
        # ì‹¤ì œ vs CTGAN
        ctgan_ks, _ = stats.ks_2samp(real_data[var], ctgan_data[var])
        # ì‹¤ì œ vs TabDDPM  
        tabddpm_ks, _ = stats.ks_2samp(real_data[var], tabddpm_data[var])
        
        similarity_scores[var] = {
            'CTGAN': 1 - ctgan_ks,  # 1-KSë¡œ ìœ ì‚¬ì„± ì ìˆ˜ ê³„ì‚°
            'TabDDPM': 1 - tabddpm_ks
        }
    
    # ìœ ì‚¬ì„± ì ìˆ˜ ì‹œê°í™”
    plt.figure(figsize=(10, 6))
    x = np.arange(len(key_vars))
    width = 0.35
    
    ctgan_scores = [similarity_scores[var]['CTGAN'] for var in key_vars]
    tabddpm_scores = [similarity_scores[var]['TabDDPM'] for var in key_vars]
    
    plt.bar(x - width/2, ctgan_scores, width, label='CTGAN', color='skyblue', alpha=0.8)
    plt.bar(x + width/2, tabddpm_scores, width, label='TabDDPM', color='lightcoral', alpha=0.8)
    
    plt.xlabel('Variables')
    plt.ylabel('Distribution Similarity Score')
    plt.title('Distribution Similarity Comparison\n(Higher is Better)')
    plt.xticks(x, key_vars)
    plt.legend()
    plt.grid(True, alpha=0.3, axis='y')
    plt.ylim(0, 1)
    
    plt.tight_layout()
    plt.show()
    
    print("ë¶„í¬ ìœ ì‚¬ì„± ì ìˆ˜:")
    for var in key_vars:
        print(f"  {var}: CTGAN={similarity_scores[var]['CTGAN']:.3f}, "
              f"TabDDPM={similarity_scores[var]['TabDDPM']:.3f}")

def comprehensive_evaluation_summary():
    """ì¢…í•© í‰ê°€ ìš”ì•½"""
    print("\n" + "="*50)
    print("ğŸ“Š í•©ì„±ë°ì´í„° í’ˆì§ˆ í‰ê°€ ì¢…í•© ê²°ê³¼")
    print("="*50)
    
    real_data = load_data()
    ctgan_data, tabddpm_data = generate_synthetic_samples(real_data)
    
    # 1. KS Distance í‰ê°€
    ctgan_ks = calculate_ks_distances(real_data, ctgan_data)
    tabddpm_ks = calculate_ks_distances(real_data, tabddpm_data)
    ctgan_ks_mean = np.mean(list(ctgan_ks.values()))
    tabddpm_ks_mean = np.mean(list(tabddpm_ks.values()))
    
    # 2. ìƒê´€ê´€ê³„ ë³´ì¡´ë„ í‰ê°€
    ctgan_retention, _, _ = calculate_correlation_retention(real_data, ctgan_data)
    tabddpm_retention, _, _ = calculate_correlation_retention(real_data, tabddpm_data)
    
    # 3. ì¢…í•© ì ìˆ˜ ê³„ì‚° (KSëŠ” ë‚®ì„ìˆ˜ë¡, ë³´ì¡´ë„ëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    ctgan_score = (1 - ctgan_ks_mean) * 0.5 + ctgan_retention * 0.5
    tabddpm_score = (1 - tabddpm_ks_mean) * 0.5 + tabddpm_retention * 0.5
    
    # ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(12, 8))
    
    # ì„œë¸Œí”Œë¡¯ êµ¬ì„±
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. KS Distance ë¹„êµ
    models = ['CTGAN', 'TabDDPM']
    ks_means = [ctgan_ks_mean, tabddpm_ks_mean]
    axes[0,0].bar(models, ks_means, color=['skyblue', 'lightcoral'], alpha=0.8)
    axes[0,0].set_title('Average KS Distance\n(Lower is Better)')
    axes[0,0].set_ylabel('KS Distance')
    for i, v in enumerate(ks_means):
        axes[0,0].text(i, v + 0.001, f'{v:.3f}', ha='center', va='bottom')
    
    # 2. ìƒê´€ê´€ê³„ ë³´ì¡´ë„ ë¹„êµ
    retentions = [ctgan_retention, tabddpm_retention]
    axes[0,1].bar(models, retentions, color=['skyblue', 'lightcoral'], alpha=0.8)
    axes[0,1].set_title('Correlation Retention\n(Higher is Better)')
    axes[0,1].set_ylabel('Retention Score')
    axes[0,1].set_ylim(0, 1)
    for i, v in enumerate(retentions):
        axes[0,1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
    
    # 3. ì¢…í•© ì ìˆ˜
    total_scores = [ctgan_score, tabddpm_score]
    axes[1,0].bar(models, total_scores, color=['skyblue', 'lightcoral'], alpha=0.8)
    axes[1,0].set_title('Overall Quality Score\n(Higher is Better)')
    axes[1,0].set_ylabel('Quality Score')
    axes[1,0].set_ylim(0, 1)
    for i, v in enumerate(total_scores):
        axes[1,0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
    
    # 4. ë ˆì´ë” ì°¨íŠ¸
    categories = ['KS Distance\n(Inverted)', 'Correlation\nRetention', 'Overall\nQuality']
    ctgan_values = [1-ctgan_ks_mean, ctgan_retention, ctgan_score]
    tabddpm_values = [1-tabddpm_ks_mean, tabddpm_retention, tabddpm_score]
    
    angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()
    angles += angles[:1]  # ì›í˜•ìœ¼ë¡œ ë§Œë“¤ê¸°
    ctgan_values += ctgan_values[:1]
    tabddpm_values += tabddpm_values[:1]
    
    axes[1,1].plot(angles, ctgan_values, 'o-', linewidth=2, label='CTGAN', color='blue')
    axes[1,1].fill(angles, ctgan_values, alpha=0.25, color='blue')
    axes[1,1].plot(angles, tabddpm_values, 'o-', linewidth=2, label='TabDDPM', color='red')
    axes[1,1].fill(angles, tabddpm_values, alpha=0.25, color='red')
    
    axes[1,1].set_xticks(angles[:-1])
    axes[1,1].set_xticklabels(categories)
    axes[1,1].set_ylim(0, 1)
    axes[1,1].set_title('Quality Metrics Radar Chart')
    axes[1,1].legend()
    axes[1,1].grid(True)
    
    plt.suptitle('Synthetic Data Quality Evaluation Summary', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # í…ìŠ¤íŠ¸ ìš”ì•½
    print(f"ğŸ¯ KS Distance: CTGAN={ctgan_ks_mean:.3f}, TabDDPM={tabddpm_ks_mean:.3f}")
    print(f"ğŸ”— Correlation Retention: CTGAN={ctgan_retention:.3f}, TabDDPM={tabddpm_retention:.3f}")
    print(f"ğŸ† Overall Quality: CTGAN={ctgan_score:.3f}, TabDDPM={tabddpm_score:.3f}")
    print(f"âœ¨ ìš°ìˆ˜ ëª¨ë¸: {'TabDDPM' if tabddpm_score > ctgan_score else 'CTGAN'}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í•©ì„±ë°ì´í„° í’ˆì§ˆ í‰ê°€ ì‹œê°í™” ì‹œì‘")
    print("="*50)
    
    # 1. KS Distance ë¶„ì„
    visualize_ks_distances()
    
    # 2. ìƒê´€ê´€ê³„ ë³´ì¡´ë„ ë¶„ì„  
    visualize_correlation_retention()
    
    # 3. ë¶„í¬ ë¹„êµ ë¶„ì„
    visualize_distribution_comparison()
    
    # 4. ì¢…í•© í‰ê°€
    comprehensive_evaluation_summary()
    
    print("\nâœ… í•©ì„±ë°ì´í„° í’ˆì§ˆ í‰ê°€ ì™„ë£Œ!")
    print("ğŸ“‹ ë³´ê³ ì„œìš© ì£¼ìš” ì§€í‘œ:")
    print("   - KS Distance: ë¶„í¬ ìœ ì‚¬ì„± ì¸¡ì •")
    print("   - Correlation Retention: ë³€ìˆ˜ê°„ ê´€ê³„ ë³´ì¡´ë„")
    print("   - Distribution Visualization: ì‹œê°ì  ë¶„í¬ ë¹„êµ")

if __name__ == "__main__":
    main()